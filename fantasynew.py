# -*- coding: utf-8 -*-
"""FantasyNew.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FwsvXHf4nJg5MRhMoKyUCsWvi29CY6Ki
"""

#imports
!pip install nfl_data_py
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
import nfl_data_py as nfl
#from google.colab import drive1
#drive.mount('/content/drive')
#PATH = '/content/drive/My Drive/'
#data = pd.read_csv(PATH + "38274-0001-Data.csv")

#https://github.com/blnkpagelabs/nflscraPy
#https://github.com/nflverse/nflverse-data
#use https://pypi.org/project/nfl-data-py/
#IF ALl else fails:
#https://github.com/bendominguez0111/data
#regress based on one variable
#or use stathead/pro football reference https://www.pro-football-reference.com/about/coverage.htm
#dictionary of all the players ever
#[]

#grab all offensive players, regress fantasy points

years = [2020, 2021]
#columns = none
nfl.import_weekly_data(years)
nfl.see_weekly_cols()
#nfl.import_rosters(years, columns)
# player name, position, position group (offense only)
#RB: carries,  rushing_yards,
#nfl.import_depth_charts(years)
#nfl.import_injuries(years)

#RB: arries', 'rushing_yards', 'rushing_tds', 'rushing_fumbles',
#       'rushing_fumbles_lost', 'rushing_first_downs', 'rushing_epa',
#       'rushing_2pt_conversions',

#test: compare fantasy points ppr


#start with just seasonal and depth chart

#TAKE all the quarterbacks from many years (20 YEARS), all the years of range
#https://pypi.org/project/nfl-data-py/
all = ['player_id', 'player_name', 'player_display_name', 'position']

#RBData = nfl.import_weekly_data(years, ["player_id", "player_name", "position", season], downcast)
#nfl.import_seasonal_data(years)

#WRData =
#QBData =

data = nfl.import_seasonal_data(years)
#a.cols()
list(data)
data = nfl.clean_nfl_data(data)
#qbdata = data.iloc(position='')
rbdata = data.iloc("position"=='RB')

'''
df = df.groupby(['player_id', 'tm', 'player', 'pos', 'season'], as_index=False)\
    .agg({
    'offensive_snapcount': np.sum,
    'offensive_snapcount_percentage': np.mean,
    'passing_rating': np.mean,
    'passing_yds': np.sum,
    'passing_td': np.sum,
    'passing_att': np.sum,
    'receiving_yds': np.sum,
    'receiving_td': np.sum,
    'receiving_rec': np.sum,
    'receiving_tar': np.sum,
    'rushing_att': np.sum,
    'standard_fantasy_points': np.sum,
    'ppr_fantasy_points': np.sum,
    'half_ppr_fantasy_points': np.sum
})
'''

#for loop: for each player in the array
  # for
  #add a new column array

#tedata =
#wrdata =
#list(rbdata)
#data.head()

'''
list(data)
for season in seasons:
  if there is a next season, add it to answer array
  otherwise, don't, but make sure the shapes are the same
'''

WIDE RECEIVER
[]
df.loc[:, "position"] = ["WR"]
'receptions',
 'targets',
 'receiving_yards',
 'receiving_tds',
 'receiving_fumbles',
 'receiving_fumbles_lost',
 'receiving_air_yards',
 'receiving_yards_after_catch'

years = [year for year in range(1999, 2021)]
data = nfl.import_seasonal_data(years)
#a.cols()
list(data)
data = nfl.clean_nfl_data(data)

dfWR = pd.DataFrame(data, columns=['player_id','games','fantasy_points_ppr', 'receptions',
  'targets',
  'receiving_yards',
  'receiving_tds',
  'receiving_fumbles',
  'receiving_fumbles_lost',
  'receiving_air_yards',
  'tgt_sh'
  'yac_sh'
])
dfWR.head()
#dfWR.shape

rbdata2 = rbdata.drop(columns=["player_id,"])

#TRANSFORM + DISCRETIZE DATA
from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()
#discretize

le.fit(data["GENDER"])
print(le.classes_)
data["GENDER"] = le.transform(data["GENDER"])
#print(le.inverse_transform([1]))
le.fit(data["RACE_REC"])
print(le.classes_)
data["RACE_REC"] = le.transform(data["RACE_REC"])

le.fit(data["OFFENSE_TYPE"])
print(le.classes_)
data["OFFENSE_TYPE"] = le.transform(data["OFFENSE_TYPE"])
print(le.inverse_transform([1]))
le.fit(data["COUNTY"])
print(le.classes_)
data["COUNTY"] = le.transform(data["COUNTY"])

le.fit(data["CRIME_RECODE"])
print(le.classes_)
data["CRIME_RECODE"] = le.transform(data["CRIME_RECODE"])

#le.fit(data["CC_DOMCHARGETYPE_END"])
#print(le.classes_)
#data["CC_DOMCHARGETYPE_END"] = le.transform(data["CC_DOMCHARGETYPE_END"])

#drop missing data columns
data = data.drop(columns=["CC_DOMCHARGETYPE_END"])
data = data.drop(columns=["DC_ALLDROP"])
data = data.drop(columns=["CONV_CC"])
data = data.drop(columns=["NOCONV_CC"])
data = data.drop(columns=["END_IN_DC"])

#drop "answer" columns
data = data.drop(columns=["DC_CONV"])
data = data.drop(columns=["FEL_CONV"])
#data = data.drop(columns=["FEL_GJ"])
data = data.drop(columns=["MISD_CONV"])
data = data.drop(columns=["ANY_INC"])

#drop irrelevant
#data = data.drop(columns=["YEAR_DCDISP"])
#data = data.drop(columns=["COUNTY"])

#data.head()

#split into train and test data
from sklearn.model_selection import train_test_split
X = data.drop(columns=["ANY_CONVICT"])
y = data["ANY_CONVICT"]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
#data.shape
data.head()
data.shape

from sklearn.model_selection import train_test_split
X = data.drop(columns=["ANY_CONVICT"])
y = data["ANY_CONVICT"]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)